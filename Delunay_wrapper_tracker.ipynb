{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84eff178-9f73-43f1-8be2-c46d802671a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import dlib\n",
    "import scipy\n",
    "import cvlib as cv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d7e39bf-180b-4b21-ab28-7104f197b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #img1=cv2.imread('./chahat_c.jpeg')\n",
    "# #img1_2=cv2.imread('./nitin.jpg')\n",
    "\n",
    "# img1=cv2.imread('./joker-2-joaquin-phoenix-batman-robert-pattinson-1186783.jpg')\n",
    "# img=img1.copy()\n",
    "# img2=img1.copy()\n",
    "# img1_gray=cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "# #img2_gray=cv2.cvtColor(img1_2,cv2.COLOR_BGR2GRAY)\n",
    "# #img1=cv2.resize(img1,(500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3701ec9a-19fe-4f89-b9fa-902e1bfd688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x=dlib.rectangle(2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d38112f-921f-49c1-865b-e341f3531d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.top()\n",
    "# plt.imshow(img1,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "85e1ccec-2631-4c5d-a244-6b9c478517af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detect_face(img1_gray,mode,path):\n",
    "#     hog_detector=dlib.get_frontal_face_detector()\n",
    "#     hog_predictor=dlib.shape_predictor(path)\n",
    "#     rects=hog_detector(img1_gray,2)\n",
    "#     no_of_faces=len(rects)\n",
    "#     print(rects)\n",
    "#     # print()\n",
    "#     if mode==1:\n",
    "#         tracker = cv2.TrackerMIL_create()\n",
    "#         ok = tracker.init(img1_gray, (rects[0].left(),rects[0].top(),rects[0].right()-rects[0].left(),rects[0].bottom()-rects[0].top()))\n",
    "#         return no_of_faces,hog_predictor,rects,tracker\n",
    "#     if mode==2:\n",
    "#         tracker = cv2.TrackerMIL_create()\n",
    "#         tracker1 = cv2.TrackerMIL_create()\n",
    "\n",
    "#         print((rects[1].left(),rects[1].top(),rects[1].right()-rects[1].left(),rects[1].bottom()-rects[1].top()))\n",
    "#         return no_of_faces,hog_predictor,rects,tracker,tracker1\n",
    "def track_face(img1_gray,tracker,tracker1,mode):\n",
    "    hog_detector=dlib.get_frontal_face_detector()\n",
    "    hog_predictor=dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')\n",
    "    rects=hog_detector(img1_gray,2)\n",
    "    no_of_faces=len(rects)\n",
    "    bbox=[]\n",
    "    if mode==1:\n",
    "        ok, bbox1 = tracker.update(img1_gray)\n",
    "        box1=np.zeros(4)\n",
    "        box1[0]=bbox1[0]\n",
    "        box1[1]=bbox1[1]\n",
    "        box1[2]=bbox1[0]+bbox1[2]\n",
    "        box1[3]=bbox1[1]+bbox1[3]\n",
    "        return no_of_faces,hog_predictor,box1\n",
    "    if mode==2:\n",
    "        box1=np.zeros(4)\n",
    "        box2=np.zeros(4)\n",
    "        ok, bbox1 = tracker.update(img1_gray)\n",
    "        ok, bbox2 = tracker1.update(img1_gray)\n",
    "        box1[0]=bbox1[0]\n",
    "        box1[1]=bbox1[1]\n",
    "        box2[0]=bbox2[0]\n",
    "        box2[1]=bbox2[1]\n",
    "        \n",
    "        box1[2]=bbox1[0]+bbox1[2]\n",
    "        box1[3]=bbox1[1]+bbox1[3]\n",
    "        box2[2]=bbox2[0]+bbox2[2]\n",
    "        box2[3]=bbox2[1]+bbox2[3]\n",
    "        # print(box2)\n",
    "        bbox.append(dlib.rectangle(int(box1[0]),int(box1[1]),int(box1[2]),int(box1[3])))\n",
    "        bbox.append(dlib.rectangle(int(box2[0]),int(box2[1]),int(box2[2]),int(box1[3])))\n",
    "        # bbox.append(box1)\n",
    "        # bbox.append(box2)\n",
    "        return no_of_faces,hog_predictor,bbox\n",
    "\n",
    "# for face in faces:    \n",
    "    # (startX,startY) = face[0],face[1]\n",
    "    # (endX,endY) = face[2],face[3]    # draw rectangle over face\n",
    "    # cv2.rectangle(img1, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "def detect_face(img1_gray,path):\n",
    "    hog_detector=dlib.get_frontal_face_detector()\n",
    "    \n",
    "    # hog_predictor=dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')\n",
    "    hog_predictor=dlib.shape_predictor(path)\n",
    "    rects=hog_detector(img1_gray,2)\n",
    "    \n",
    "    no_of_faces=len(rects)\n",
    "    return no_of_faces,hog_predictor,rects\n",
    "def detect_face_cnn(img1_gray,img1,path,mode):\n",
    "    hog_detector=dlib.get_frontal_face_detector()\n",
    "    \n",
    "    # hog_predictor=dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')\n",
    "    hog_predictor=dlib.shape_predictor(path)\n",
    "    rects=hog_detector(img1_gray,2)\n",
    "    face, confidences = cv.detect_face(img1,0.29)\n",
    "    rects=[]\n",
    "    # print(face)\n",
    "    if mode==2:\n",
    "        if len(face)!=2:\n",
    "            return 0,hog_predictor,rects\n",
    "        rects.append(dlib.rectangle(int(face[0][0]),int(face[0][1]),int(face[0][2]),int(face[0][3])))\n",
    "        rects.append(dlib.rectangle(int(face[1][0]),int(face[1][1]),int(face[1][2]),int(face[1][3])))\n",
    "    if mode==1:\n",
    "        if len(face)==0:\n",
    "                   return 0,hog_predictor,rects\n",
    "        rects.append(dlib.rectangle(int(face[0][0]),int(face[0][1]),int(face[0][2]),int(face[0][3])))\n",
    "        \n",
    "    # faces, confidences = cv.detect_face(img1_gray,0.25)\n",
    "    no_of_faces=len(rects)\n",
    "    return no_of_faces,hog_predictor,rects\n",
    "\n",
    "# def landmarks_extraction(img1_gray,hog_predictor,rects):\n",
    "#     # bounding_box=[]\n",
    "#     # multi_img_face_lm=[]\n",
    "\n",
    "#     # landmarks_index_list=[]\n",
    "#     landmarks_index={}\n",
    "#     x_=(hog_predictor(img1_gray,rects))\n",
    "#     facial_landmarks=np.array([[x_.part(i).x ,x_.part(i).y] for i in range(68) ])\n",
    "#     #if iter_landmarks==1:\n",
    "#     for ind,val in enumerate(facial_landmarks):\n",
    "#         landmarks_index[tuple(val)]=ind\n",
    "#     # landmarks_index_list.append(landmarks_index)\n",
    "#     # multi_img_face_lm.append(facial_landmarks)\n",
    "#     bounding=[]\n",
    "\n",
    "#     bounding.append((rects.left(),rects.top(),rects.right(),rects.bottom()))    \n",
    "\n",
    "#     # bounding_box.append(x)\n",
    "#     return bounding,landmarks_index,facial_landmarks\n",
    "def landmarks_extraction(img1_gray,hog_predictor,rects):\n",
    "    # bounding_box=[]\n",
    "    # multi_img_face_lm=[]\n",
    "\n",
    "    # landmarks_index_list=[]\n",
    "    landmarks_index={}\n",
    "    x_=(hog_predictor(img1_gray,rects))\n",
    "    facial_landmarks=np.array([[x_.part(i).x ,x_.part(i).y] for i in range(68) ])\n",
    "    #if iter_landmarks==1:\n",
    "    for ind,val in enumerate(facial_landmarks):\n",
    "        landmarks_index[tuple(val)]=ind\n",
    "    # landmarks_index_list.append(landmarks_index)\n",
    "    # multi_img_face_lm.append(facial_landmarks)\n",
    "    bounding=[]\n",
    "\n",
    "    bounding.append((rects.left(),rects.top(),rects.right(),rects.bottom()))     \n",
    "\n",
    "    # bounding_box.append(x)\n",
    "    return bounding,landmarks_index,facial_landmarks\n",
    "\n",
    "def get_bounding_box(facial_landmarks):\n",
    "    x,y,w,h=(cv2.boundingRect(cv2.convexHull(facial_landmarks)))\n",
    "    \n",
    "    return ((x,y),(x+w,y+h)),cv2.Subdiv2D((x,y,x+w,y+h))\n",
    "def disp_landmarks_face(img1,facial_landmarks,rect):\n",
    "    for i in range(68): \n",
    "        cv2.circle(img1,facial_landmarks[i][:],color=[255,255,255],radius=5,thickness=2)\n",
    "    img1=cv2.rectangle(img1,rect[0], rect[1],color=[255,255,255],thickness=5)\n",
    "    return img1\n",
    "\n",
    "def delunay_triangle(subdiv2,multi_img_face_lm):\n",
    "    delunay_traingle_pts_list=[]\n",
    "    # print((multi_img_face_lm[0].shape))\n",
    "    iter_for_sub=0\n",
    "    # subdiv2[0].insert((int(multi_img_face_lm[0][0][0]),int(multi_img_face_lm[0][0][1])))\n",
    "    for sub in subdiv2:\n",
    "\n",
    "        #print(len(multi_img_face_lm))\n",
    "        i=1\n",
    "        for p in multi_img_face_lm[iter_for_sub].tolist():\n",
    "\n",
    "            # print(i)\n",
    "            #print(p)\n",
    "            i=i+1\n",
    "            sub.insert((p[0],p[1]))\n",
    "        delunay_traingle_pts_list.append(sub.getTriangleList())\n",
    "        iter_for_sub=1\n",
    "    return delunay_traingle_pts_list[0]\n",
    "\n",
    "def check_point(pts,box):\n",
    "    (xmin,ymin),(xmax,ymax)=box\n",
    "\n",
    "    if pts[0]>=xmin and pts[1]>=ymin and pts[0]<=xmax and pts[1]<=ymax:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def matching_delunay_triangles(delunay_triangle_pts_list,rect_,landmarks_index_list,img1,multi_img_face_lm):\n",
    "\n",
    "    sorted_delunay_lists=[]\n",
    "    sorting_index_for_delunay_list=[]\n",
    "    iter_=0\n",
    "    #for delunay_traingle_points,landmark_index_ in zip(delunay_traingle_pts_list,landmarks_index_list):\n",
    "    index_array_img=[]\n",
    "    sorted_delunay_pts1=[]\n",
    "    sorted_delunay_pts2=[]\n",
    "    sorting_index_for_delunay=[]\n",
    "    for p in delunay_triangle_pts_list:\n",
    "        pts1=(int(p[0]),int(p[1]))\n",
    "        pts2=(int(p[2]),int(p[3]))    \n",
    "        pts3=(int(p[4]),int(p[5]))        \n",
    "        #print(pts1)\n",
    "        box=rect_[iter_]\n",
    "        if check_point(pts1,box) and check_point(pts2,box) and check_point(pts3,box)  :\n",
    "            pts_vector1=np.array([pts1,pts2,pts3])\n",
    "            pts_vector2=np.zeros(pts_vector1.shape,dtype=np.int32)\n",
    "            #print(pts_vector1)\n",
    "            #index_array=np.zeros(3)\n",
    "            #for \n",
    "            index_array=[]\n",
    "            index=landmarks_index_list[0].get(tuple(pts1),False)\n",
    "            if index:\n",
    "                #index_array[0]=index\n",
    "                index_array.append(index)\n",
    "                pts_vector2[0]=multi_img_face_lm[1][index]\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "            index=landmarks_index_list[0].get(tuple(pts2),False)\n",
    "            #pts_vector2[0]=multi_img_face_lm[0][index]\n",
    "            if index:\n",
    "                # index_array[1]=index\n",
    "                index_array.append(index)\n",
    "                pts_vector2[1]=multi_img_face_lm[1][index]\n",
    "            else:\n",
    "                continue\n",
    "            index=landmarks_index_list[0].get(tuple(pts3),False)\n",
    "            if index:\n",
    "                # index_array[2]=index\n",
    "                index_array.append(index)\n",
    "                pts_vector2[2]=multi_img_face_lm[1][index]\n",
    "                #print(pts_vector)\n",
    "            else:\n",
    "                continue\n",
    "            #index_add.append()\n",
    "            if len(index_array)!=3:\n",
    "                print('False')\n",
    "            index_array=np.array(index_array)\n",
    "            index_to_sort=np.argsort(index_array)\n",
    "            index_array=index_array[index_to_sort]\n",
    "            pts_vector1=pts_vector1[index_to_sort,:]\n",
    "            pts_vector2=pts_vector2[index_to_sort,:]\n",
    "            #print(pts_vector.shape)\n",
    "            inds=''\n",
    "            #print(index_array)\n",
    "\n",
    "            for ind_x in index_array:\n",
    "                ind_x=int(ind_x)\n",
    "                inds=inds+str(ind_x)\n",
    "            index_array_img.append(int(inds))\n",
    "            #index_array_img.append(index_array)\n",
    "            sorted_delunay_pts1.append(pts_vector1)\n",
    "            sorted_delunay_pts2.append(pts_vector2)\n",
    "            # cv2.line(img1,pts1,pts2,[255,0, 255],1)\n",
    "            # cv2.line(img1,pts3,pts2,[255,0,255],1)\n",
    "            # cv2.line(img1,pts3,pts1,[255,0,255],1)\n",
    "            # cv2.line(img1,(pts_vector2[0,0],pts_vector2[0,1]),(pts_vector2[1,0],pts_vector2[1,1]),[255,0, 255],1)\n",
    "            # cv2.line(img1,(pts_vector2[2,0],pts_vector2[2,1]),(pts_vector2[1,0],pts_vector2[1,1]),[255,0,255],1)\n",
    "            # cv2.line(img1,(pts_vector2[2,0],pts_vector2[2,1]),(pts_vector2[0,0],pts_vector2[0,1]),[255,0,255],1)\n",
    "    iter_=iter_+1\n",
    "    sorted_delunay_pts1=np.array(sorted_delunay_pts1)\n",
    "    sorted_delunay_pts2=np.array(sorted_delunay_pts2)\n",
    "    sorted_delunay_lists.append(sorted_delunay_pts1)\n",
    "    sorted_delunay_lists.append(sorted_delunay_pts2)\n",
    "\n",
    "    index_array_img=np.array(index_array_img)\n",
    "\n",
    "    sorting_index_for_delunay_list.append(index_array_img)\n",
    "    return img1,sorted_delunay_lists,sorting_index_for_delunay_list\n",
    "    # def delunay_triangles()\n",
    "def global_cord_img(x_,y_,h_,w_):\n",
    "    l1=np.arange(x_,x_+h_)\n",
    "    l2=np.arange(y_,y_+w_)\n",
    "    a=np.meshgrid(l1,l2)\n",
    "    a=np.array(a)\n",
    "    #a\n",
    "    a=np.moveaxis(a,0,-1)\n",
    "    ones=np.ones((a.shape[0],a.shape[1],1))\n",
    "    g_cord=np.concatenate([a,ones],-1)\n",
    "    return g_cord\n",
    "#delunay_traingle_points[0]\n",
    "def bilinear_interpolate(im, x, y):\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    x0 = np.floor(x).astype(int)\n",
    "    x1 = x0 + 1\n",
    "    y0 = np.floor(y).astype(int)\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    x0 = np.clip(x0, 0, im.shape[1]-1);\n",
    "    x1 = np.clip(x1, 0, im.shape[1]-1);\n",
    "    y0 = np.clip(y0, 0, im.shape[0]-1);\n",
    "    y1 = np.clip(y1, 0, im.shape[0]-1);\n",
    "    #coords=np.array([[x0,x1,x1,x0],[y0,y1,y0,y1]])\n",
    "    Ia = im[ y0, x0 ]\n",
    "    Ib = im[ y1, x0 ]\n",
    "    Ic = im[ y0, x1 ]\n",
    "    Id = im[ y1, x1 ]\n",
    "\n",
    "    wa = (x1-x) * (y1-y)\n",
    "    wb = (x1-x) * (y-y0)\n",
    "    wc = (x-x0) * (y1-y)\n",
    "    wd = (x-x0) * (y-y0)\n",
    "    wa=np.tile(wa,(3,1)).T\n",
    "    wb=np.tile(wb,(3,1)).T\n",
    "    wc=np.tile(wc,(3,1)).T\n",
    "    wd=np.tile(wd,(3,1)).T\n",
    "    return wa*Ia + wb*Ib + wc*Ic + wd*Id\n",
    "# bounded_array_f=0\n",
    "def image_warping(del_tri_pts1,del_tri_pts2,img2,img3,img2_black,img3_black):\n",
    "\n",
    "    x_,y_,h_,w_=cv2.boundingRect((del_tri_pts1.reshape(3,2)))\n",
    "\n",
    "    bounded_array=global_cord_img(x_-2,y_-2,h_+2,w_+2)\n",
    "    m,n,z=bounded_array.shape\n",
    "    bounded_array=np.reshape(bounded_array,(m*n,z))\n",
    "\n",
    "    B=np.ones((3,3))\n",
    "    B[0:2,:]=del_tri_pts1.reshape(3,2).T\n",
    "    if np.linalg.det(B)!=0:\n",
    "        B_inv=np.linalg.inv(B)\n",
    "    else:\n",
    "        B_inv=np.linalg.pinv(B)\n",
    "\n",
    "    bayesian_coordinates=(B_inv@bounded_array.T).T\n",
    "\n",
    "    zero_arr_1=np.all(bayesian_coordinates<=1.01 ,axis=1)\n",
    "    zero_arr_2=np.all(bayesian_coordinates>=-0.01,axis=1)\n",
    "    # print(zero_arr_1.shape)\n",
    "    zero_arr=(zero_arr_1 * zero_arr_2)\n",
    "\n",
    "    zero_condition_1=np.stack((zero_arr,zero_arr,zero_arr)).T\n",
    "\n",
    "    mask=zero_condition_1\n",
    "    x11=bayesian_coordinates\n",
    "    bayesian_coordinates_f=np.multiply(bayesian_coordinates,mask)\n",
    "    bounded_array_f=np.multiply(bounded_array,mask)\n",
    "    bounded_array_f=bounded_array_f[~np.all((bayesian_coordinates_f)==0,axis=1)]\n",
    "    bayesian_coordinates_f=bayesian_coordinates_f[~np.all((bayesian_coordinates_f)==0,axis=1)]\n",
    "\n",
    "    A=np.ones((3,3))\n",
    "    A[0:2,:]=del_tri_pts2.reshape(3,2).T\n",
    "    if bayesian_coordinates_f.shape[0]!=0:\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        A_coord=A@bayesian_coordinates_f.T\n",
    "        # print(A_coord.shape)\n",
    "        # print(bayesian_coordinates_f.shape)\n",
    "        A_coord=A_coord/A_coord[-1]\n",
    "        bounded_array_f=bounded_array_f.T\n",
    "        # print(bounded_array_f[-1])\n",
    "        bounded_array_f=bounded_array_f/bounded_array_f[-1]\n",
    "        bounded_array_f=(bounded_array_f).astype(np.int32)\n",
    "        # print(bounded_array_f.shape)\n",
    "        A_coord=(A_coord).astype(np.int32)\n",
    "        temp=img2[bounded_array_f[1,:],bounded_array_f[0,:]].copy()\n",
    "\n",
    "        img3[bounded_array_f[1,:],bounded_array_f[0,:]] = img2[A_coord[1,:],A_coord[0,:]].copy()\n",
    "        # img3[A_coord[1,:],A_coord[0,:]]=img2[bounded_array_f[1,:],bounded_array_f[0,:]]\n",
    "        # img2_black[bounded_array_f[1,:],bounded_array_f[0,:]] = img2[A_coord[1,:],A_coord[0,:]]\n",
    "        \n",
    "    \n",
    "def whole_image_warp_delunay(img1,img2_,del_x,del_y):   \n",
    "    #A_coord\n",
    "    img1_black=np.zeros(img2_.shape,dtype=np.uint8)\n",
    "    img2_black=np.zeros(img2_.shape,dtype=np.uint8)\n",
    "\n",
    "    # img2_=img1.copy()\n",
    "\n",
    "    # for i in range(len(delunay_triangle_pts_list[0])):\n",
    "    #     image_warping(delunay_triangle_pts_list[0][i],delunay_triangle_pts_list[1][i],img1,img2_,img1_black,img2_black)\n",
    "    for i in range(len(del_x)):\n",
    "        image_warping(del_x[i],del_y[i],img1,img2_,img1_black,img2_black)\n",
    "    return img2_,img1_black\n",
    "\n",
    "def posisson_blending(src,dst,mx,rects):\n",
    "    poly_left = cv2.convexHull(mx)#img2[op[:,1],op[:,0]]#np.array([(51, 228), (100, 151), (233, 102), (338, 110), (426, 160), (373, 252), (246, 284), (134, 268)], np.int32)\n",
    "\n",
    "    src_mask = np.zeros((dst.shape), dst.dtype)\n",
    "    src_mask=cv2.fillPoly(src_mask, [poly_left], (255,255,255))\n",
    "    # plt.imshow(src_mask)\n",
    "    im1=cv2.seamlessClone(src,dst,src_mask,(int((rects[1][0]+rects[0][0])/2),int((rects[1][1]+rects[0][1])/2)),cv2.NORMAL_CLONE)\n",
    "    #im1=cv2.seamlessClone(src,dest,src_mask1,(int((rects[0][1][0]+rects[0][0][0])/2),int((rects[0][1][1]+rects[0][0][1])/2)),cv2.NORMAL_CLONE)\n",
    "    return im1\n",
    "\n",
    "from scipy.spatial import distance\n",
    "def distance_function(pts1,pts1_): #compute r^2xlog(r^2)\n",
    "    diff_pts=(pts1-pts1_)\n",
    "    #r_sq=distance.cdist(pts1,pts1_,'sqeuclidean')\n",
    "    r=np.linalg.norm(diff_pts)\n",
    "    # r=np.sqrt(r)\n",
    "    # r_sq=np.square(r)\n",
    "    r_sq=r\n",
    "    #print(np.log(r_sq))\n",
    "    \n",
    "    U=np.multiply((r_sq**2),np.log(r_sq+1e-5\n",
    "                               ))    #print(U)\n",
    "    return U\n",
    "    \n",
    "\n",
    "def global_cord_img(x_,y_,h_,w_):\n",
    "    l1=np.arange(x_,x_+h_+2)\n",
    "    l2=np.arange(y_,y_+w_+2)\n",
    "    a=np.meshgrid(l1,l2)\n",
    "    a=np.array(a)\n",
    "    #a\n",
    "    a=np.moveaxis(a,0,-1)\n",
    "    # print(a.shape)\n",
    "    ones=np.ones((a.shape[0],a.shape[1],1))\n",
    "    # print(a[:,1])\n",
    "    g_cord=np.concatenate([a,ones],-1)\n",
    "    return g_cord\n",
    "\n",
    "def distanc_function_forward(patch,reference,weights):\n",
    "    patch=np.tile(patch[:,:2],(68,1,1,))\n",
    "    # print(patch.shape)\n",
    "    _,w,h=patch.shape\n",
    "    reference=np.tile(np.expand_dims(reference,1),(1,w,1))\n",
    "    # print(reference.shape)\n",
    "    diff_pts=(patch-reference)\n",
    "    \n",
    "    r=np.linalg.norm(diff_pts,axis=-1)\n",
    "    \n",
    "    # r=np.sqrt(r)\n",
    "    # r_sq=np.square(r)\n",
    "    r_sq=r\n",
    "    U=(r_sq**2)*np.log(r_sq+1e-5)\n",
    "    # print(r.shape)\n",
    "    w,h=r.shape\n",
    "    weights=weights[:-3,:]\n",
    "    #weights=np.expand_dims(weights,-1)\n",
    "    #weights_exp=np.tile(weights,(1,w,h))\n",
    "    \n",
    "    # weights_ex\n",
    "    summation=U.T@weights\n",
    "    # print(summation.shape)\n",
    "    return summation#.shape\n",
    "def weights_for_tps(mx,my):\n",
    "    lm_w,lm_h=mx.shape\n",
    "    k=np.zeros((lm_w,lm_w))\n",
    "    for i_ in range(len(mx)):\n",
    "        #for j_ in range(i_,len(multi_img_face_lm[0])):\n",
    "        for j_ in range(len(mx)):\n",
    "            k[i_,j_]=distance_function(my[i_],my[j_])\n",
    "\n",
    "\n",
    "    P=np.ones((lm_w,3))\n",
    "    P[:,0]=my[:,1]\n",
    "    P[:,1]=my[:,0]\n",
    "    A_=np.zeros((lm_w+3,lm_w+3))\n",
    "    A_[:-3,:-3]=k\n",
    "    A_[:-3,-3:]=P\n",
    "    A_[-3:,:-3]=P.T\n",
    "    I=np.identity(A_.shape[0])\n",
    "    lamda=1e-3\n",
    "    A=A_+lamda*I\n",
    "    A_inv=np.linalg.inv(A)\n",
    "    x_coord_zeros=np.zeros((A_.shape[0],1))\n",
    "    x_coord_zeros[:-3,0]=mx[:,0]\n",
    "    y_coord_zeros=np.zeros((A_.shape[0],1))\n",
    "    y_coord_zeros[:-3,0]=mx[:,1]\n",
    "\n",
    "\n",
    "\n",
    "    weights_x=A_inv @ x_coord_zeros\n",
    "    weights_y=A_inv @ y_coord_zeros\n",
    "    return weights_x,weights_y\n",
    "def tps_swaping(mx,my,img2,img3,weights_x,weights_y):\n",
    "    poly_left = cv2.convexHull(my)#img2[op[:,1],op[:,0]]#np.array([(51, 228), (100, 151), (233, 102), (338, 110), (426, 160), (373, 252), (246, 284), (134, 268)], np.int32)\n",
    "\n",
    "\n",
    "    src_mask = np.zeros((img3.shape[0],img3.shape[1]), img3.dtype)\n",
    "    src_mask=cv2.fillPoly(src_mask, [poly_left], (255))\n",
    "    x,y=np.where(src_mask==255)\n",
    "    coordinate_x=np.ones((x.shape[0],3))\n",
    "    coordinate_x[:,0]=x\n",
    "    coordinate_x[:,1]=y\n",
    "    # corcy=multi_img_face_lm[0]\n",
    "    mask=255*np.ones(img2.shape)\n",
    "    mask=np.uint8(mask)\n",
    "    # mask.shape\n",
    "\n",
    "    m,n,_=img2.shape\n",
    "    poly_left = cv2.convexHull(my)\n",
    "\n",
    "    #plt.imshow(src_mask)\n",
    "    corcx=mx.copy()#multi_img_face_lm[0].copy()\n",
    "    corcx[:,0]=my[:,1].copy()\n",
    "    corcx[:,1]=my[:,0].copy()\n",
    "\n",
    "    x,y=np.where(src_mask==255)\n",
    "    op_x=(coordinate_x @weights_x[-3:,:])+distanc_function_forward(coordinate_x,corcx,weights_x)\n",
    "    op_y=(coordinate_x @weights_y[-3:,:])+distanc_function_forward(coordinate_x,corcx,weights_y)\n",
    "    op_x=np.reshape(op_x,(op_x.shape[0]*op_x.shape[1],1))\n",
    "    op_y=np.reshape(op_y,(op_y.shape[0]*op_y.shape[1],1))\n",
    "\n",
    "    op=np.concatenate((op_x,op_y),axis=-1)\n",
    "    # # coordinate_x.shape\n",
    "    op=np.array(op,np.int32)\n",
    "    coordinate_x1=np.array(coordinate_x,dtype=np.int32)\n",
    "\n",
    "    # img3_=np.zeros(img2.shape)\n",
    "    # img3=img2.copy()\n",
    "    temp=img3[op[:,1],op[:,0]]\n",
    "\n",
    "\n",
    "    # img2[op[:,1],op[:,0]]=img3[coordinate_x1[:,0],coordinate_x1[:,1]]\n",
    "    img2[coordinate_x1[:,0],coordinate_x1[:,1]]=temp\n",
    "    # img3_[op[:,1],op[:,0]]=img2[coordinate_x1[:,0],coordinate_x1[:,1]]\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e029891-5c67-4a6a-89d6-110f316de6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Parser = argparse.ArgumentParser()\n",
    "Parser.add_argument('--method', default=\"DelTri\", help='type of Faceswapper:DelTri, TPspline,PRNet')\n",
    "Parser.add_argument('--DataPath', default=\"./TestSet_P2/\", help='base path where data files exist')\n",
    "Parser.add_argument('--VideoName', default=\"Test2.mp4\", help='Video Name')\n",
    "Parser.add_argument('--RefImageName', default='NONE', help=' Reference Image')\n",
    "Parser.add_argument('--SavePath', default=\"./Results/\", help='Folder to save results')\n",
    "Parser.add_argument('--LandmarkPath', default='./shape_predictor_68_face_landmarks.dat', help= 'dlib shape predictor path')\n",
    "\n",
    "\n",
    "Args = Parser.parse_args(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a53a15bf-e72a-4e50-bf8c-cb72fa4c8543",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 't'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_492821/2713398668.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 't'"
     ]
    }
   ],
   "source": [
    "cv2.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0f011847-b546-4d8f-bbb3-292c5a8c56a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "25f04d88-d073-42a9-9199-d59f296c4db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ref image.......\n",
      "2 face video\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@8055.783] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('./TestSet_P2/None'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    Parser = argparse.ArgumentParser()\n",
    "    Parser.add_argument('--method', default=\"DelTri\", help='type of Faceswapper:DelTri, TPspline,PRNet')\n",
    "    Parser.add_argument('--DataPath', default=\"./TestSet_P2/\", help='base path where data files exist')\n",
    "    Parser.add_argument('--VideoName', default=\"Test2.mp4\", help='Video Name')\n",
    "    Parser.add_argument('--RefImageName', default='None', help=' Reference Image')\n",
    "    Parser.add_argument('--SavePath', default=\"./Results/\", help='Folder to save results')\n",
    "    Parser.add_argument('--LandmarkPath', default='./shape_predictor_68_face_landmarks.dat', help= 'dlib shape predictor path')\n",
    "    \n",
    "\n",
    "    Args = Parser.parse_args(\"\")\n",
    "    DataPath = Args.DataPath\n",
    "    RefImageName = Args.RefImageName\n",
    "    SavePath = Args.SavePath\n",
    "    method = Args.method\n",
    "    VideoName = Args.VideoName\n",
    "    LM_path = Args.LandmarkPath\n",
    "    RefImageFilePath = DataPath + RefImageName\n",
    "    VideoFilePath = DataPath + VideoName\n",
    "     \n",
    "    # SaveFileName = DataPath + SavePath \n",
    "    SaveFileName = SavePath +method+ VideoName\n",
    "    print('Reading ref image.......')\n",
    "    FaceRef = cv2.imread(RefImageFilePath) ## color image\n",
    " \n",
    "    if FaceRef is None:\n",
    "        mode = 2\n",
    "        print('2 face video')\n",
    "    else:\n",
    "        mode = 1\n",
    "        print('1 face video')\n",
    "    import matplotlib.pyplot as plt\n",
    "    cap=cv2.VideoCapture(VideoFilePath)\n",
    "    for i in range(1):\n",
    "        _,im=cap.read()\n",
    "    m,n,_=im.shape\n",
    "    out=cv2.VideoWriter(SaveFileName,cv2.VideoWriter_fourcc(*'mp4v'), 30, (n,m))\n",
    "    if mode==2:\n",
    "        if method!='PRNet':\n",
    "            ret,img1=cap.read()\n",
    "            img1_gray=cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "            no_of_faces,hog_predictor,rects=detect_face_cnn(img1_gray,img1,LM_path,mode)\n",
    "            tracker = cv2.TrackerMIL_create()\n",
    "            tracker1 = cv2.TrackerMIL_create()\n",
    "            prev_rects=rects\n",
    "            # tracker = cv2.TrackerMIL_create()\n",
    "            # tracker1 = cv2.TrackerMIL_create()\n",
    "            ok = tracker.init(img1, (rects[0].left(),rects[0].top(),rects[0].right()-rects[0].left(),rects[0].bottom()-rects[0].top()))\n",
    "            ok=tracker1.init(img1,(rects[1].left(),rects[1].top(),rects[1].right()-rects[1].left(),rects[1].bottom()-rects[1].top()))\n",
    "            # print((rects[1].left(),rects[1].top(),rects[1].right()-rects[1].left(),rects[1].bottom()-rects[1].top()))\n",
    "            while cap.isOpened():\n",
    "                print(1)\n",
    "                ret,img1=cap.read()\n",
    "                \n",
    "                if ret==False:\n",
    "                    break\n",
    "                img=img1.copy()\n",
    "                img2=img1.copy()\n",
    "                img1_gray=cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "                no_of_faces,hog_predictor,rects=detect_face_cnn(img1_gray,img1,LM_path,mode)\n",
    "\n",
    "                # no_of_faces,hog_predictor,rects,tracker,tracker1=detect_face(img1_gray,mode,LM_path)\n",
    "                if no_of_faces!=2  :\n",
    "                    \n",
    "                    rects=prev_rects\n",
    "                    ok = tracker.init(img1_gray, (rects[0].left(),rects[0].top(),rects[0].right()-rects[0].left(),rects[0].bottom()-rects[0].top()))\n",
    "                    ok = tracker1.init(img1_gray,(rects[1].left(),rects[1].top(),rects[1].right()-rects[1].left(),rects[1].bottom()-rects[1].top()))\n",
    "                    no_of_faces,hog_predictor,bbox=track_face(img1_gray,tracker,tracker1,mode)\n",
    "                    rects=bbox\n",
    "#                 prev_rects=rects\n",
    "#                 if rects[0].left()-prev_rects[0].left()>30 or rects[0].left()-prev_rects[0].left()>30 or rects[1].left()-prev_rects[1].left()>30 or rects[1].left()-prev_rects[1].left()>30  :\n",
    "                    \n",
    "#                     rects=prev_rects\n",
    "#                     ok = tracker.init(img1_gray, (rects[0].left(),rects[0].top(),rects[0].right()-rects[0].left(),rects[0].bottom()-rects[0].top()))\n",
    "#                     ok = tracker1.init(img1_gray,(rects[1].left(),rects[1].top(),rects[1].right()-rects[1].left(),rects[1].bottom()-rects[1].top()))\n",
    "#                     no_of_faces,hog_predictor,bbox=track_face(img1_gray,tracker,tracker1,mode)\n",
    "                prev_rects=rects\n",
    "                # print(no_of_faces)\n",
    "                #and no_of_faces==2:\n",
    "                subdiv2=[]\n",
    "                bounding_box=[]\n",
    "                multi_img_face_lm=[]\n",
    "\n",
    "                landmarks_index_list=[]\n",
    "                rect_=[]\n",
    "\n",
    "                # return bounding,landmarks_index,facial_landmarks\n",
    "                bounding,landmarks_index,facial_landmarks=landmarks_extraction(img1_gray,hog_predictor,rects[0])\n",
    "                bounding_box.append(bounding)\n",
    "                multi_img_face_lm.append(facial_landmarks)\n",
    "                landmarks_index_list.append(landmarks_index)\n",
    "\n",
    "                bounding,landmarks_index,facial_landmarks=landmarks_extraction(img1_gray,hog_predictor,rects[1])\n",
    "                bounding_box.append(bounding)\n",
    "                multi_img_face_lm.append(facial_landmarks)\n",
    "                landmarks_index_list.append(landmarks_index)\n",
    "\n",
    "                rect1,subdiv1=(get_bounding_box(multi_img_face_lm[0]))\n",
    "                rect_.append(rect1)\n",
    "                subdiv2.append(subdiv1)\n",
    "\n",
    "                rect2,subdiv1=(get_bounding_box(multi_img_face_lm[1]))\n",
    "                rect_.append(rect2)\n",
    "                subdiv2.append(subdiv1)\n",
    "                # print(mode)\n",
    "                if method=='DelTri': \n",
    "                    delunay_traingle_pts_list=delunay_triangle(subdiv2,multi_img_face_lm)\n",
    "                    img_with_delunay_pts,sorted_delunay_lists,sorting_index_for_delunay_list=matching_delunay_triangles(delunay_traingle_pts_list,rect_,landmarks_index_list,img1.copy(),multi_img_face_lm)\n",
    "                    delunay_triangle_pts_list=sorted_delunay_lists\n",
    "                    img2_=img1.copy()\n",
    "                    img1_black=np.zeros(img2.shape,dtype=np.uint8)\n",
    "                    img2_black=np.zeros(img2.shape,dtype=np.uint8)\n",
    "\n",
    "                    im1,im1b=whole_image_warp_delunay(img1.copy(),img1.copy(),delunay_triangle_pts_list[0].copy(),delunay_triangle_pts_list[1].copy())\n",
    "                    im1,im1b=whole_image_warp_delunay(img1.copy(),im1,delunay_triangle_pts_list[1].copy(),delunay_triangle_pts_list[0].copy())\n",
    "                    im=im1\n",
    "\n",
    "                    rects=rect_\n",
    "                    # print(rects.shape)\n",
    "                    im1=posisson_blending(im,img2,multi_img_face_lm[1],rects[1])\n",
    "                    im1=posisson_blending(im,im1,multi_img_face_lm[0],rects[0])\n",
    "                    cv2.imshow('Frame',im1)\n",
    "                    #cv2.imwrite(\"im1_d.jpg\",im1)\n",
    "                    #plt.imshow(im1)\n",
    "                    key = cv2.waitKey(1)\n",
    "                    # print(i_)\n",
    "                    # i_=i_+1\n",
    "                    out.write(im1)\n",
    "                    # print('3')\n",
    "                    if key == ord('q'):\n",
    "\n",
    "                      break\n",
    "                elif method=='TPspline':\n",
    "                    rects=rect_\n",
    "                    weights_x,weights_y=weights_for_tps(multi_img_face_lm[0],multi_img_face_lm[1])\n",
    "                    im=tps_swaping(multi_img_face_lm[0].copy(),multi_img_face_lm[1].copy(),img2.copy(),img2.copy(),weights_x,weights_y)\n",
    "\n",
    "\n",
    "                    weights_x,weights_y=weights_for_tps(multi_img_face_lm[1],multi_img_face_lm[0])\n",
    "                    im=tps_swaping(multi_img_face_lm[1].copy(),multi_img_face_lm[0].copy(),im.copy(),img2.copy(),weights_x,weights_y)\n",
    "\n",
    "\n",
    "                    im1=posisson_blending(im,img2,multi_img_face_lm[1],rects[1])\n",
    "                    im1=posisson_blending(im,im1,multi_img_face_lm[0],rects[0])\n",
    "                    cv2.imshow('Frame',im1)\n",
    "\n",
    "                    # 20 is in milliseconds, try to increase the value, say 50 and observe\n",
    "                    key = cv2.waitKey(1)\n",
    "\n",
    "                    out.write(im1)\n",
    "                    if key == ord('q'):\n",
    "\n",
    "                      break\n",
    "            \n",
    "            cap.release()\n",
    "\n",
    "            out.release()\n",
    "            cv2.destroyAllWindows()\n",
    "    if mode==1:\n",
    "        if method!='PRNet':\n",
    "            re_=1\n",
    "            rects=[]\n",
    "            rect1=[]\n",
    "            ret,img1=cap.read()\n",
    "            while len(rect1)==0:\n",
    "                ret,img1=cap.read()\n",
    "                img2=FaceRef\n",
    "\n",
    "\n",
    "                img1_gray=cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "                no_of_faces,hog_predictor,rect1=detect_face_cnn(img1_gray,img1,LM_path,mode)\n",
    "                img2_gray=cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                no_of_faces,hog_predictor2,rect2_=detect_face_cnn(img2_gray,img2,LM_path,mode)\n",
    "            rects.append(rect1[0])\n",
    "            rects.append(rect2_[0])\n",
    "            print(rect1)\n",
    "            tracker = cv2.TrackerMIL_create()\n",
    "            tracker1 = cv2.TrackerMIL_create()\n",
    "            prev_rects=rects\n",
    "            # tracker = cv2.TrackerMIL_create()\n",
    "            # tracker1 = cv2.TrackerMIL_create()\n",
    "            ok = tracker.init(img1, (rects[0].left(),rects[0].top(),rects[0].right()-rects[0].left(),rects[0].bottom()-rects[0].top()))\n",
    "\n",
    "            while cap.isOpened():\n",
    "                # print(1)\n",
    "                ret,img1=cap.read()\n",
    "                \n",
    "                if ret==False:\n",
    "                    break\n",
    "                img=img1.copy()\n",
    "                \n",
    "                img1_gray=cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "                no_of_faces_,hog_predictor,rects=detect_face_cnn(img1_gray,img1,LM_path,mode)\n",
    "                cv2.imshow(\"img2\",img2_gray)\n",
    "                no_of_faces,hog_predictor2,rect2_=detect_face_cnn(img2_gray,img2,LM_path,mode)\n",
    "                rects.append(rect2_[0])\n",
    "                # rects=re\n",
    "                # no_of_faces,hog_predictor,rects,tracker,tracker1=detect_face(img1_gray,mode,LM_path)\n",
    "                if no_of_faces_!=1  :\n",
    "                    \n",
    "                    rects=prev_rects\n",
    "                    ok = tracker.init(img1_gray, (rects[0].left(),rects[0].top(),rects[0].right()-rects[0].left(),rects[0].bottom()-rects[0].top()))\n",
    "                    # ok = tracker1.init(img1_gray,(rects[1].left(),rects[1].top(),rects[1].right()-rects[1].left(),rects[1].bottom()-rects[1].top()))\n",
    "                    no_of_faces,hog_predictor,bbox=track_face(img1_gray,tracker,tracker,mode)\n",
    "                    rects=bbox\n",
    "#                 prev_rects=rects\n",
    "#                 if rects[0].left()-prev_rects[0].left()>30 or rects[0].left()-prev_rects[0].left()>30 or rects[1].left()-prev_rects[1].left()>30 or rects[1].left()-prev_rects[1].left()>30  :\n",
    "                    \n",
    "#                     rects=prev_rects\n",
    "#                     ok = tracker.init(img1_gray, (rects[0].left(),rects[0].top(),rects[0].right()-rects[0].left(),rects[0].bottom()-rects[0].top()))\n",
    "#                     ok = tracker1.init(img1_gray,(rects[1].left(),rects[1].top(),rects[1].right()-rects[1].left(),rects[1].bottom()-rects[1].top()))\n",
    "#                     no_of_faces,hog_predictor,bbox=track_face(img1_gray,tracker,tracker1,mode)\n",
    "                prev_rects=rects\n",
    "                # print(no_of_faces)\n",
    "                #and no_of_faces==2:\n",
    "                subdiv2=[]\n",
    "                bounding_box=[]\n",
    "                multi_img_face_lm=[]\n",
    "\n",
    "                landmarks_index_list=[]\n",
    "                rect_=[]\n",
    "\n",
    "                # return bounding,landmarks_index,facial_landmarks\n",
    "                bounding,landmarks_index,facial_landmarks=landmarks_extraction(img1_gray,hog_predictor,rects[0])\n",
    "                bounding_box.append(bounding)\n",
    "                multi_img_face_lm.append(facial_landmarks)\n",
    "                landmarks_index_list.append(landmarks_index)\n",
    "                # print('1',rects[0],rects[1])\n",
    "                bounding,landmarks_index,facial_landmarks=landmarks_extraction(img2_gray,hog_predictor2,rects[1])\n",
    "                bounding_box.append(bounding)\n",
    "                multi_img_face_lm.append(facial_landmarks)\n",
    "                landmarks_index_list.append(landmarks_index)\n",
    "                \n",
    "                rect1,subdiv1=(get_bounding_box(multi_img_face_lm[0]))\n",
    "                rect_.append(rect1)\n",
    "                subdiv2.append(subdiv1)\n",
    "\n",
    "                rect2,subdiv1=(get_bounding_box(multi_img_face_lm[1]))\n",
    "                rect_.append(rect2)\n",
    "                subdiv2.append(subdiv1)\n",
    "                # print(mode)\n",
    "                if method=='DelTri': \n",
    "                    delunay_traingle_pts_list=delunay_triangle(subdiv2,multi_img_face_lm)\n",
    "                    img_with_delunay_pts,sorted_delunay_lists,sorting_index_for_delunay_list=matching_delunay_triangles(delunay_traingle_pts_list,rect_,landmarks_index_list,img1.copy(),multi_img_face_lm)\n",
    "                    delunay_triangle_pts_list=sorted_delunay_lists\n",
    "                    # img2_=img1.copy()\n",
    "                    img1_black=np.zeros(img2.shape,dtype=np.uint8)\n",
    "                    img2_black=np.zeros(img2.shape,dtype=np.uint8)\n",
    "                    \n",
    "                    im1,im1b=whole_image_warp_delunay(img2.copy(),img1.copy(),delunay_triangle_pts_list[0].copy(),delunay_triangle_pts_list[1].copy())\n",
    "                    # im1,im1b=whole_image_warp_delunay(img1.copy(),im1,delunay_triangle_pts_list[1].copy(),delunay_triangle_pts_list[0].copy())\n",
    "                    im=im1\n",
    "\n",
    "                    rects=rect_\n",
    "                    # print(rects.shape)\n",
    "                    im1=posisson_blending(im,img1,multi_img_face_lm[0],rects[0])\n",
    "                    # im1=posisson_blending(im,im1,multi_img_face_lm[0],rects[0])\n",
    "                    cv2.imshow('Frame',im1)\n",
    "                    #cv2.imwrite(\"im1_d.jpg\",im1)\n",
    "                    #plt.imshow(im1)\n",
    "                    key = cv2.waitKey(1)\n",
    "                    # print(i_)\n",
    "                    # i_=i_+1\n",
    "                    out.write(im1)\n",
    "                    # print('3')\n",
    "                    if key == ord('q'):\n",
    "\n",
    "                      break\n",
    "                elif method=='TPspline':\n",
    "                    rects=rect_\n",
    "                    weights_x,weights_y=weights_for_tps(multi_img_face_lm[1],multi_img_face_lm[0])\n",
    "                    im=tps_swaping(multi_img_face_lm[1].copy(),multi_img_face_lm[0].copy(),img1.copy(),img2.copy(),weights_x,weights_y)\n",
    "\n",
    "\n",
    "                    # weights_x,weights_y=weights_for_tps(multi_img_face_lm[1],multi_img_face_lm[0])\n",
    "                    # im=tps_swaping(multi_img_face_lm[1].copy(),multi_img_face_lm[0].copy(),im.copy(),img2.copy(),weights_x,weights_y)\n",
    "\n",
    "\n",
    "                    # im1=posisson_blending(im,img1,multi_img_face_lm[1],rects[1])\n",
    "                    im1=posisson_blending(im,img1,multi_img_face_lm[0],rects[0])\n",
    "                    cv2.imshow('Frame',im1)\n",
    "\n",
    "                    # 20 is in milliseconds, try to increase the value, say 50 and observe\n",
    "                    key = cv2.waitKey(1)\n",
    "\n",
    "                    out.write(im1)\n",
    "                    if key == ord('q'):\n",
    "\n",
    "                      break\n",
    "            \n",
    "            cap.release()\n",
    "\n",
    "            out.release()\n",
    "            cv2.destroyAllWindows()\n",
    "if __name__ =='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d47a7-a9c2-4931-87d7-4d908896c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tbimg1_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f78dee-8233-4a84-af36-9969b362fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rects=hog_detector(img2_gray)\n",
    "import matplotlib.pyplot as plt\n",
    "cap=cv2.VideoCapture('./TestSet_P2/Test2.mp4')\n",
    "for i in range(1):\n",
    "    _,im=cap.read()\n",
    "m,n,_=im.shape\n",
    "out=cv2.VideoWriter('outpy_d.mp4',cv2.VideoWriter_fourcc(*'mp4v'), 10, (n,m))\n",
    "# out=cv2.VideoWriter('outpy_d.mp4',cv2.VideoWriter_fourcc(*'mp4v'), 10, (n,m))\n",
    "i_=0\n",
    "while (cap.isOpened()):\n",
    "    # print(1)\n",
    "    ret,img1=cap.read()\n",
    "    if ret==False:\n",
    "        break\n",
    "    img=img1.copy()\n",
    "    img2=img1.copy()\n",
    "    img1_gray=cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "    no_of_faces,hog_predictor,rects=detect_face(img1_gray,'./shape_predictor_68_face_landmarks.dat')\n",
    "    subdiv2=[]\n",
    "    bounding_box=[]\n",
    "    multi_img_face_lm=[]\n",
    "\n",
    "    landmarks_index_list=[]\n",
    "    rect_=[]\n",
    "    if no_of_faces==2:\n",
    "        bounding,landmarks_index,facial_landmarks=landmarks_extraction(img1_gray,hog_predictor,rects[0])\n",
    "        bounding_box.append(bounding)\n",
    "        multi_img_face_lm.append(facial_landmarks)\n",
    "        landmarks_index_list.append(landmarks_index)\n",
    "\n",
    "        bounding,landmarks_index,facial_landmarks=landmarks_extraction(img1_gray,hog_predictor,rects[1])\n",
    "        bounding_box.append(bounding)\n",
    "        multi_img_face_lm.append(facial_landmarks)\n",
    "        landmarks_index_list.append(landmarks_index)\n",
    "\n",
    "        rect1,subdiv1=(get_bounding_box(multi_img_face_lm[0]))\n",
    "        rect_.append(rect1)\n",
    "        subdiv2.append(subdiv1)\n",
    "\n",
    "        rect2,subdiv1=(get_bounding_box(multi_img_face_lm[1]))\n",
    "        rect_.append(rect2)\n",
    "        subdiv2.append(subdiv1)\n",
    "\n",
    "        img_with_landmark=disp_landmarks_face(img1.copy(),multi_img_face_lm[0],rect_[0])\n",
    "        img_with_landmark=disp_landmarks_face(img_with_landmark,multi_img_face_lm[1],rect_[1])\n",
    "        # plt.imshow(img_with_landmark)\n",
    "        delunay_traingle_pts_list=delunay_triangle(subdiv2,multi_img_face_lm)\n",
    "        img_with_delunay_pts,sorted_delunay_lists,sorting_index_for_delunay_list=matching_delunay_triangles(delunay_traingle_pts_list,rect_,landmarks_index_list,img1.copy(),multi_img_face_lm)\n",
    "        delunay_triangle_pts_list=sorted_delunay_lists\n",
    "        # im1,im1b=whole_image_warp_delunay(img1.copy(),img1.copy())\n",
    "        # print(delunay_triangle_pts_list)\n",
    "        img2_=img1.copy()\n",
    "        img1_black=np.zeros(img2.shape,dtype=np.uint8)\n",
    "        img2_black=np.zeros(img2.shape,dtype=np.uint8)\n",
    "        # for i in range(len(delunay_triangle_pts_list[0])):\n",
    "        #     image_warping(delunay_triangle_pts_list[0][i],delunay_triangle_pts_list[1][i],img1,img2_,img1_black,img2_black)\n",
    "        im1,im1b=whole_image_warp_delunay(img1.copy(),img1.copy(),delunay_triangle_pts_list[0].copy(),delunay_triangle_pts_list[1].copy())\n",
    "        im1,im1b=whole_image_warp_delunay(img1.copy(),im1,delunay_triangle_pts_list[1].copy(),delunay_triangle_pts_list[0].copy())\n",
    "        im=im1\n",
    "        rects=rect_\n",
    "        im1=posisson_blending(im,img2,multi_img_face_lm[1],rects[1])\n",
    "        im1=posisson_blending(im,im1,multi_img_face_lm[0],rects[0])\n",
    "        cv2.imshow('Frame',im1)\n",
    "        #cv2.imwrite(\"im1_d.jpg\",im1)\n",
    "        #plt.imshow(im1)\n",
    "        key = cv2.waitKey(1)\n",
    "        # print(i_)\n",
    "        i_=i_+1\n",
    "        out.write(im1)\n",
    "        if key == ord('q'):\n",
    "\n",
    "          break\n",
    "\n",
    "\n",
    "        #plt.imshow(im1)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    " \n",
    "        # break\n",
    "#multi_img_face_lm=np.array(multi_img_face_lm)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9043a9-dfc9-46da-8fa7-223778fa3e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdiv2\n",
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc411ee-5cc7-4163-8ac1-cf771dae223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "delunay_triangle_pts_list[0].shape\n",
    "#delunay_traingle_pts_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4415d-8ffd-44dd-9d82-1b080238a796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76120da9-f9d3-4aba-b8cf-88cf1401d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf1f081-4f9c-4511-992c-4e1e4eca2adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img2_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e7c3a-08fe-40cc-8ac6-f245a5ac6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img1_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c11776-5534-4c62-9801-ab2e035c4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img1_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5435a2b5-cbf9-4b69-947c-02c91328993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(1,3):\n",
    "\n",
    "    #print(j)\n",
    "    img1_1=cv2.rectangle(img1.copy(),(bounding_box[j-1][0][0],bounding_box[j-1][0][1]),(bounding_box[j-1][0][2],bounding_box[j-1][0][3]),color=[255,0,255],thickness=5)\n",
    "    #j=1\n",
    "\n",
    "\n",
    "j=2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce88a05-c962-4b8b-9d44-41118dd26348",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img1_1,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea77ae4d-c9a9-4cd4-8078-327b68d828b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(landmarks_index_list[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f07b7-5780-4f0c-8e19-03d25b41a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_img_face_lm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae4993-6582-462c-a35a-6541796c64f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdiv2=[]\n",
    "rect_=[]\n",
    "for i in range(2):\n",
    "    x,y,w,h=(cv2.boundingRect(cv2.convexHull(multi_img_face_lm[i])))\n",
    "    subdiv2.append(cv2.Subdiv2D((x,y,x+w,y+h)))\n",
    "    rect_.append(((x,y),(x+w,y+h)))\n",
    "#rect1=cv2.boundingRect(rect[1])\n",
    "rect_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b9c29a-7910-4ef8-89c4-81b649140ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rect in rect_:\n",
    "    \n",
    "    plt.imshow(cv2.rectangle(img,rect[0],rect[1],[255,255,255],5))\n",
    "plt.imshow(img.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbe1ff-b53c-44c1-9718-772b3e644baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_for_sub=0 \n",
    "        \n",
    "        #print(i)\n",
    "        i+=1\n",
    "    iter_for_sub+=1\n",
    "    #print(tuple(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd0ad8-a0b3-48a7-b609-a67a645c1fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "delunay_traingle_pts_list=[]\n",
    "for sub in subdiv2:\n",
    "    delunay_traingle_pts_list.append(sub.getTriangleList())\n",
    "\n",
    "def check_point(pts,box):\n",
    "    (xmin,ymin),(xmax,ymax)=box\n",
    "   # xmax,ymax= xmin+w,ymin+h\n",
    "    if pts[0]>xmin and pts[1]>ymin and pts[0]<xmax and pts[1]<ymax:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "sorted_delunay_lists=[]\n",
    "sorting_index_for_delunay_list=[]\n",
    "iter_=0\n",
    "#for delunay_traingle_points,landmark_index_ in zip(delunay_traingle_pts_list,landmarks_index_list):\n",
    "index_array_img=[]\n",
    "sorted_delunay_pts1=[]\n",
    "sorted_delunay_pts2=[]\n",
    "sorting_index_for_delunay=[]\n",
    "for p in delunay_traingle_pts_list[0]:\n",
    "    pts1=(int(p[0]),int(p[1]))\n",
    "    pts2=(int(p[2]),int(p[3]))    \n",
    "    pts3=(int(p[4]),int(p[5]))        \n",
    "    #print(pts1)\n",
    "    box=rect_[iter_]\n",
    "    if check_point(pts1,box) and check_point(pts2,box) and check_point(pts3,box) or True :\n",
    "        pts_vector1=np.array([pts1,pts2,pts3])\n",
    "        pts_vector2=np.zeros(pts_vector1.shape,dtype=np.int32)\n",
    "        #print(pts_vector1)\n",
    "        #index_array=np.zeros(3)\n",
    "        #for \n",
    "        index_array=[]\n",
    "        index=landmarks_index_list[0].get(tuple(pts1),False)\n",
    "        if index:\n",
    "            #index_array[0]=index\n",
    "            index_array.append(index)\n",
    "            pts_vector2[0]=multi_img_face_lm[1][index]\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "        index=landmarks_index_list[0].get(tuple(pts2),False)\n",
    "        #pts_vector2[0]=multi_img_face_lm[0][index]\n",
    "        if index:\n",
    "            # index_array[1]=index\n",
    "            index_array.append(index)\n",
    "            pts_vector2[1]=multi_img_face_lm[1][index]\n",
    "        else:\n",
    "            continue\n",
    "        index=landmarks_index_list[0].get(tuple(pts3),False)\n",
    "        if index:\n",
    "            # index_array[2]=index\n",
    "            index_array.append(index)\n",
    "            pts_vector2[2]=multi_img_face_lm[1][index]\n",
    "            #print(pts_vector)\n",
    "        else:\n",
    "            continue\n",
    "        #index_add.append()\n",
    "        if len(index_array)!=3:\n",
    "            print('False')\n",
    "        index_array=np.array(index_array)\n",
    "        index_to_sort=np.argsort(index_array)\n",
    "        index_array=index_array[index_to_sort]\n",
    "        pts_vector1=pts_vector1[index_to_sort,:]\n",
    "        pts_vector2=pts_vector2[index_to_sort,:]\n",
    "        #print(pts_vector.shape)\n",
    "        inds=''\n",
    "        #print(index_array)\n",
    "\n",
    "        for ind_x in index_array:\n",
    "            ind_x=int(ind_x)\n",
    "            inds=inds+str(ind_x)\n",
    "        index_array_img.append(int(inds))\n",
    "        #index_array_img.append(index_array)\n",
    "        sorted_delunay_pts1.append(pts_vector1)\n",
    "        sorted_delunay_pts2.append(pts_vector2)\n",
    "        cv2.line(img1,pts1,pts2,[255,0, 255],1)\n",
    "        cv2.line(img1,pts3,pts2,[255,0,255],1)\n",
    "        cv2.line(img1,pts3,pts1,[255,0,255],1)\n",
    "        cv2.line(img1,(pts_vector2[0,0],pts_vector2[0,1]),(pts_vector2[1,0],pts_vector2[1,1]),[255,0, 255],1)\n",
    "        cv2.line(img1,(pts_vector2[2,0],pts_vector2[2,1]),(pts_vector2[1,0],pts_vector2[1,1]),[255,0,255],1)\n",
    "        cv2.line(img1,(pts_vector2[2,0],pts_vector2[2,1]),(pts_vector2[0,0],pts_vector2[0,1]),[255,0,255],1)\n",
    "iter_=iter_+1\n",
    "sorted_delunay_pts1=np.array(sorted_delunay_pts1)\n",
    "sorted_delunay_pts2=np.array(sorted_delunay_pts2)\n",
    "sorted_delunay_lists.append(sorted_delunay_pts1)\n",
    "sorted_delunay_lists.append(sorted_delunay_pts2)\n",
    "\n",
    "index_array_img=np.array(index_array_img)\n",
    "\n",
    "sorting_index_for_delunay_list.append(index_array_img)\n",
    "#break\n",
    "#index=np.argsort(sorting_index_for_delunay_list[0])\n",
    "#sorting_index_for_delunay_list[0]=sorting_index_for_delunay_list[0][index]\n",
    "#sorted_delunay_lists[0]=sorted_delunay_lists[0][index]\n",
    "#index=np.argsort(sorting_index_for_delunay_list[1])\n",
    "#sorting_index_for_delunay_list[1]=sorting_index_for_delunay_list[1][index]\n",
    "#sorted_delunay_lists[1]=sorted_delunay_lists[1][index]\n",
    "#sorted_delunay_lists[1]=sorted_delunay_lists[1][index]\n",
    "#index\n",
    "#index_array_img\n",
    "#sorting_index_for_delunay_list[0]\n",
    "#sorting_index_for_delunay_list[1]\n",
    "delunay_traingle_pts_list=sorted_delunay_lists\n",
    "# temp=delunay_traingle_pts_list[0]\n",
    "# delunay_traingle_pts_list[0]=delunay_traingle_pts_list[1]\n",
    "# delunay_traingle_pts_list[1]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba77b68f-ae64-41f2-a52f-7cce176cc4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "delunay_traingle_pts_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62440ed8-5571-4adb-9e9b-1095927ecf02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70260eb-3343-471e-8d80-571a6ce465c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2D = np.array([[11, 12, 13, 22], [21, 7, 23, 14], [31, 10, 33, 7]])\n",
    "array1D=[20,10,30]\n",
    "arr2D[np.argsort(array1D),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf1f02e-b636-43dd-8cd0-8c84d09da80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "int('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2e57f-955e-4257-a0ad-5ed42ded437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img1)\n",
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500c262-6f08-4b42-a991-c71cbec7432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delunay_traingle_points[0].reshape(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832065e3-7cbe-44eb-9123-d9e1039d5ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delunay_traingle_points[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4ba628-d7e6-45ef-9a06-534553051114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9f8cc0-9a70-4094-ae1a-e94ebbac7062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f66e5d-9328-407f-a166-8c2aafb0fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd1da75-4fdf-4d45-b535-3800e9b92bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca78a17-9fcd-4981-9f3f-9c89de5de38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.interpolate\n",
    "scipy.interpolate.interp2d(A_coord[0,:],A_coord[1,:],img[A_coord[:,0:2],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1218dd4e-f73c-4206-9bf8-274578918494",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd7bf8-afe9-4de2-ba55-a3f384095a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "delunay_traingle_pts_list[0][i].reshape(3,2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98f2907-0c7b-4f37-8e66-8a6d1679077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounded_array_f\n",
    "img2[bounded_array_f[:,1],bounded_array_f[:,0]]\n",
    "img2[A_coord[:,1],A_coord[:,0]]\n",
    "#A_coord\n",
    "\n",
    "#A_coord/A_coord[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db86c7c8-2486-48ad-b4ac-bc37d17259c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_coordinates_f.shape\n",
    "A.shape\n",
    "#mask[bayesian_coordinates>=1]=0\n",
    "#~np.any(mask==0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c4945-b667-4967-8e51-87f34c5a97a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3e9ef6-7442-415e-ac0f-56fdf5e45203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751d161e-d541-46d0-9f2e-ea10e77f3cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c46dfde-c1ae-430a-90e6-932b2e517da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b0eb1-6251-4733-9850-fb27a7e6a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a5cc0e-4ed7-43ed-85d5-1cd97d2e20b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
